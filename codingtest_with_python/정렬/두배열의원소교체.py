# condingtest_with_python_part2_정렬
# 두배열의원소교체.py

## 두배열은 N개의 원소롤 구성되어 있고, 배열의 원소는 모두 자연수
## 최대 K번 바꿔치기 연산 가능 (바꿔치기 연산 : A의 원소 하나와 B의 원소 하나를 골라서 두 원소를 서로 바꾸는 것)
## 최종 목표는 최대 k번의 바꿔치기 연산을 수행해서 배열 A의 모든 원소의 합이 최대가 되도록 하는 것
## 입력 첫째줄 : N,K 공백으로 입력 (1<=N<=10만,0<=K<=N)
## 입력 둘쨰줄 : A의 원소들이 공백으로 구분되어 입력됨, (원소 < 천만) 
## 입력 : 셋쨰줄 : B의 원소들이 공백으로 구분되어 입력됨. (원소 < 천만) 
##  출력 :  최대 k번의 바꿔치기 연산을 수행해서 배열 A의 모든 원소의 합이 최대값을 출력

# 나의 풀이
N, K = map(int,input().split())
A = list(map(int,input().split()))
B = list(map(int,input().split()))
## 우선 범위를 확인해보면 데이터의 갯수는 10만 이하인데, 원소가 천만까지 갈 수 있으므로, 계수 정렬 못쓰고, 문제에 어떤 알고리즘을
## 사용하라는 특별한 조건이 따로 없었으므로 정렬 라이브러리를 사용하자
if len(A) == N and len(B) == N:
  A.sort() # 오름차순으로 정렬
  B.sort(reverse=True) # 내림차순으로 정렬

for i in range(K):
  if A[i] < B[i]:
    A[i], B[i] = B[i], A[i]

print(sum(A))
    
# 나의 풀이 (Product Code)
N, K = map(int,input().split()) # 배열의 원소의 개수와 바꿔치기 연산 횟수 입력받음
A = list(map(int,input().split())) # A리스트 원소 입력받음
B = list(map(int,input().split())) # B리스트 원소 입력받음
if len(A) == N and len(B) == N: # 입력받은 원소의 수가 처음에 입력받았던 배열의 원소의 개수와 같다면
  A.sort() # 오름차순으로 정렬 
  B.sort(reverse=True) # 내림차순으로 정렬(B배열에서 가장 큰 수들을 A배열의 가장 작은 수들과 바꿀 것이기 때문에 그것을 수행하기 용이하게)

# 바꿔치기 연산 수행
for i in range(K):
  if A[i] < B[i]:
    A[i], B[i] = B[i], A[i]

# A배열의 모든 원소의 합의 최댓값 출력
print(sum(A))

    
# 교재 풀이
n,k = map(int,input.split())
a = list(map(int,input().split()))
b = list(map(int,input().split()))

a.sort
b.sort(reverse=True)

for i in range(k):
  # A의 원소가 B의 원소보다 작은 경우
  if a[i] < b[i]:
    # 두원소를 교체
    a[i], b[i] = b[i], a[i]
  else: # A의 원소가 B의 원소보다 크거나 같을 때 반복문 탈출 #################################### 내풀이와 다른 것
    break

print(sum(a)) # 배열 A의 모든 원소의 합을 출력



# 느낀점
"""
문제를 풀고 해설을 읽어보며, 내가 생각했던 풀이와 해설의 풀이가 일치하였다.
그런데 간과했던 부분은 다음과 같다.
1. 원소의 개수를 고려하였으나 "원소의 개수가 최대 100,000개까지 입력될 수 있으므로 O(NlogN)을 보장하는 정렬 알고리즘을 이용해야한다"
  라는 해설의 내용을 고려하지 못했다. 
2. B의 가장 큰 원소가 A의 가장작은 원소보다 클 경우에만 교체해야된다는 것까지는 잘 하였지만
  한 번 A의 원소가 크거나 같은 경우가 나올경우 거기서 반복문을 멈춰야된다는 것을 떠올리지 못했다.
  
1 번과 관련해서는 데이터의 개수와 시간복잡도의 관계를 다시 한 번 정리해야된다는 것을 느꼈다.
2 번의 경우는 데이터가 급격하게 커질 수록 그렇지 않은 경우와 수행시간의 차이가 커질 수 있다는 것을 느꼈고
그렇기 떄문에 이러한 불필요한 연산을 수행하지 않도록 항상 유념해야겠다고 생각했다. 
"""

